{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeoLook Scraper\n",
    "* 2022.07.19a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step03: HTML 문서 분석하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장해 둔 Archive List 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47154\n",
      "['20220629f', '20220630a', '20220630b', '20220630c', '20220630d', '20220630e', '20220630f', '20220630g', '20220630h', '20220630i']\n"
     ]
    }
   ],
   "source": [
    "def readList(fileName):\n",
    "    with open(fileName, 'r') as f: \n",
    "        lines = []  \n",
    "        for line in f:\n",
    "            #print(line)\n",
    "            lines.append(line.rstrip())\n",
    "        return lines\n",
    "    print(len(lines)) \n",
    "       \n",
    "list = readList(\"archivesList/total.txt\")\n",
    "print(len(list))\n",
    "print(list[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "htmls/1989/19891106a.htm\n"
     ]
    }
   ],
   "source": [
    "def getHtmlText(fileName):\n",
    "    dir = fileName[:4]\n",
    "    file = fileName[4:]\n",
    "    path = \"htmls/\" + dir + \"/\" + fileName + \".htm\"\n",
    "    print(path)\n",
    "    with open(path, 'r', encoding='utf-8') as f: \n",
    "        return f.read()\n",
    "\n",
    "\n",
    "text = getHtmlText(list[0])\n",
    "#print(text)\n",
    "\n",
    "#testList = ['20220602a', '20220602c', '20220603i', '20220601b'] #개인전, 그룹전, 그룹전, 저널"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\baekseongyeol\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-22.2-py3-none-any.whl (2.0 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-22.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pip.exe, pip3.9.exe and pip3.exe are installed in 'C:\\Users\\BaekSeongYeol\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\baekseongyeol\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\baekseongyeol\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\baekseongyeol\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip\n",
    "! pip install bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import random # debug 용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "htmls/2008/20081120e.htm\n",
      "김난영展 / KIMNANYOUNG / 金蘭榮 / painting\n",
      "type = solo , genre = painting\n"
     ]
    }
   ],
   "source": [
    "xtra = [\"개인\", \"회화\", \"조각\", \"사진\", \"영상\", \"설치\", \"수묵\", \"서예\", \"드로잉\", \"판화\", \"도예\"]\n",
    "xtraDic = {\"개인\":\"solo\", \"회화\":\"painting\", \"조각\":\"sculpture\", \"사진\":\"photography\", \"영상\":\"video\", \"설치\":\"installation\", \"수묵\":\"painting\", \"서예\":\"calligrapht\", \"드로잉\":\"drawing\", \"판화\":\"printing\", \"도예\":\"ceramic\"}\n",
    "\n",
    "def getTypeGenre(whichVolumePage):\n",
    "    soup = bs(whichVolumePage, \"html.parser\")\n",
    "    volumeTag = soup.find(class_=\"tag\") #페이지 하단 하얀 박스에 표기된 정보\n",
    "    volumeTag = volumeTag.contents[2].strip()\n",
    "    print(volumeTag)\n",
    "\n",
    "    type = \"\"\n",
    "    genre = \"\"\n",
    "    #if(\"展\" in volumeTag):\n",
    "    if((\"展\" in volumeTag or volumeTag[-1] == \"전\" or volumeTag[-1] == \"제\") and not (\"조각회展\" in volumeTag)):\n",
    "        #volumeTag = volumeTag.split(\"/\")\n",
    "        if(len(volumeTag.split(\"/\"))>1):\n",
    "            type = \"solo\"\n",
    "            #print(\"solo\")\n",
    "            genre = volumeTag.split(\"/\")[-1].strip()            \n",
    "        elif(len(volumeTag.split(\" \"))>=2 and (volumeTag.split(\" \")[1][-1] == \"展\")):\n",
    "            #print(\"xtra?\")\n",
    "            type = \"group\"\n",
    "            #print(\"xtra group\")\n",
    "            genre = \"group\"           \n",
    "            for item in xtra:\n",
    "                last = volumeTag.split(\" \")[-1]\n",
    "                #print(\"item:\", item, \", last:\", last)\n",
    "                if(item in last):\n",
    "                    type = \"solo\"\n",
    "                    #print(\"xtra solo\")\n",
    "                    #genre = volumeTag.split(\" \")[1]\n",
    "                    #genre = genre[:-1]\n",
    "                    key = item\n",
    "                    #print(\"key =\", key)\n",
    "                    genre = xtraDic[key]\n",
    "                    break              \n",
    "                '''\n",
    "                else:\n",
    "                    type = \"group\"\n",
    "                    print(\"xtra group\")\n",
    "                    genre = \"group\"\n",
    "                    break\n",
    "                '''\n",
    "        else:\n",
    "            type = \"group\"\n",
    "            genre = \"group\"\n",
    "            print(\"group\")\n",
    "    else:\n",
    "        print(\"NOT exhibition\") \n",
    "        type = \"NA\" \n",
    "        genre = \"NA\"\n",
    "    #print(\"type:\", type)    \n",
    "    #print(\"genre:\", genre)\n",
    "    return type, genre\n",
    "\n",
    "htmlText = getHtmlText(list[random.randrange(0, 10000)])\n",
    "type, genre = getTypeGenre(htmlText)\n",
    "print(\"type =\", type, \", genre =\", genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "htmls/2008/20081008f.htm\n",
      "volumeTag: 김보라展 / KIMBORA / 金보라 / sculpture\n",
      "title: dreaming - 꿈으로 피어나다\n"
     ]
    }
   ],
   "source": [
    "def getTitle(whichVolumePage):\n",
    "    soup = bs(whichVolumePage, \"html.parser\")\n",
    "    volumeTag = soup.find(class_=\"tag\") #페이지 하단 하얀 박스에 표기된 정보\n",
    "    volumeTag = volumeTag.contents[2].strip()\n",
    "    print(\"volumeTag:\", volumeTag)\n",
    "    title = \"\"\n",
    "    h1 = soup.find(\"h1\")\n",
    "    h2 = soup.find(\"h2\")\n",
    "    if(h1 != None):\n",
    "        title = h1.text.strip()        \n",
    "    else:\n",
    "        title = h2.text.strip()\n",
    "    print(\"title:\",title)  \n",
    "    return title\n",
    "\n",
    "htmlText = getHtmlText(list[random.randrange(0, 10000)])\n",
    "title = getTitle(htmlText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "htmls/2004/20040909a.htm\n",
      "김보중 회화展\n",
      "회화展\n",
      "['김보중']\n"
     ]
    }
   ],
   "source": [
    "#import re\n",
    "\n",
    "def getSoloArtist(whichVolumePage):\n",
    "    soup = bs(whichVolumePage, \"html.parser\")\n",
    "    volumeTag = soup.find(class_=\"tag\") #페이지 하단 하얀 박스에 표기된 정보\n",
    "    volumeTag = volumeTag.contents[2].strip()\n",
    "    print(volumeTag)\n",
    "\n",
    "    artists = []\n",
    "    tags = volumeTag.split(\"/\")    \n",
    "    if(len(tags) >= 2 and tags[0].strip()[-1] == \"展\"):\n",
    "        print(\"parsed\")\n",
    "        artist = tags[0].strip()[:-1]\n",
    "        artists.append(artist)\n",
    "        #print(artists) \n",
    "    \n",
    "    tags = volumeTag.split(\" \")  \n",
    "    if(len(tags) >= 2 and tags[-1][-1].strip() == \"展\"):\n",
    "        artist = tags[0].strip()\n",
    "        artists.append(artist)\n",
    "        print(tags[-1]) \n",
    "    \n",
    "    return artists\n",
    "\n",
    "htmlText = getHtmlText(list[random.randrange(0, 10000)])\n",
    "artists = getSoloArtist(htmlText)\n",
    "print(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "htmls/2007/20070825d.htm\n",
      "T . T CLUSTER展\n",
      "['김경옥-잘림', '김은선-그림만들기', '김채린-열아홉개의', '박정흠-', '유민선', '유태준-3개의애드립', '이정진-그림을', '이주현-']\n"
     ]
    }
   ],
   "source": [
    "#import re\n",
    "\n",
    "def getGroupArtist(whichVolumePage):\n",
    "    soup = bs(whichVolumePage, \"html.parser\")\n",
    "    volumeTag = soup.find(class_=\"tag\") #페이지 하단 하얀 박스에 표기된 정보\n",
    "    volumeTag = volumeTag.contents[2].strip()\n",
    "    print(volumeTag)\n",
    "\n",
    "    artists = []\n",
    "    description = soup.find(class_=\"archives-description\")\n",
    "    dd = description.find_all(\"dd\")\n",
    "    #print(len(dd)) #캡션의 수 출력\n",
    "    for child in dd:\n",
    "        #print(child.text)\n",
    "        if(len(child.text) > 1):\n",
    "            artists.append(re.split(\" |_\", child.text.strip())[0])\n",
    "    print(artists)\n",
    "    return artists\n",
    "\n",
    "htmlText = getHtmlText(list[random.randrange(0, 10000)])\n",
    "artists = getGroupArtist(htmlText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "htmls/2006/20060314d.htm\n",
      "한국 근대 사진의 선각자들 1부展\n",
      "extra: 사진\n",
      "사진\n"
     ]
    }
   ],
   "source": [
    "#import re\n",
    "extraGenre = [\"개인\", \"화화\", \"조각\", \"목조각\", \"사진\", \"영상\", \"사진.영상\", \"설치영상\"]\n",
    "\n",
    "def getGenre(whichVolumePage):\n",
    "    soup = bs(whichVolumePage, \"html.parser\")\n",
    "    volumeTag = soup.find(class_=\"tag\") #페이지 하단 하얀 박스에 표기된 정보\n",
    "    volumeTag = volumeTag.contents[2].strip()\n",
    "    print(volumeTag)\n",
    "\n",
    "    genre = \"\"\n",
    "    if(\"展\" in volumeTag or volumeTag[-1] == \"전\"):\n",
    "        #isExhibition = True\n",
    "        #print(\"exhibition\")\n",
    "        tag = volumeTag.split(\"/\")\n",
    "        #tag = re.split(\" |/\", volumeTag.strip())\n",
    "        if(len(tag)>1):\n",
    "            genre = tag[-1].strip()            \n",
    "        else:\n",
    "            #print(tag.contents[2].strip())\n",
    "            for item in extraGenre:\n",
    "                #print(item)\n",
    "                \n",
    "                if(item in volumeTag):\n",
    "                    print(\"extra:\", item)\n",
    "                    genre = item \n",
    "                #break                             \n",
    "    else:\n",
    "        genre = \"NA\" \n",
    "        \n",
    "    if(\"공모\" in volumeTag):\n",
    "        genre = \"NA\"\n",
    "    print(genre)\n",
    "    return genre\n",
    "\n",
    "\n",
    "htmlText = getHtmlText(list[random.randrange(0, 10000)])\n",
    "genre = getGenre(htmlText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "htmls/1989/19891106b.htm\n",
      "[['이인철', '스포츠 공화국의 上下', '종이에 목판화', 'size : NA', 'year : NA'], 'https://neolook.com/archives/1989110601b.jpg']\n",
      "[['이인철', '역사의 기록', '종이에 목판화', 'size : NA', 'year : NA'], 'https://neolook.com/archives/1989110602b.jpg']\n",
      "[['이인철', '대장정', '종이에 목판화', 'size : NA', 'year : NA'], 'https://neolook.com/archives/1989110603b.jpg']\n",
      "[['이인철', '반전 반핵', '종이에 목판화', 'size : NA', 'year : NA'], 'https://neolook.com/archives/1989110604b.jpg']\n",
      "[['이인철', '머물지 못하는 사람들', '종이에 목판화', 'size : NA', 'year : NA'], 'https://neolook.com/archives/1989110605b.jpg']\n",
      "[['이인철', '하늘아 열려라', '종이에 목판화', 'size : NA', 'year : NA'], 'https://neolook.com/archives/1989110606b.jpg']\n",
      "[['이인철', '잃어버린 창', '종이에 목판화', 'size : NA', 'year : NA'], 'https://neolook.com/archives/1989110607b.jpg']\n",
      "[['이상호', '격려', 'media : NA', '18×20.5cm', '1988'], 'https://neolook.com/archives/1989110608b.jpg']\n",
      "[['이상호', '슬퍼하는 청년', 'media : NA', '22×22.5cm', '1988'], 'https://neolook.com/archives/1989110609b.jpg']\n",
      "[['이상호', '기다림', '종이에 목판화', '19×28cm', '1987'], 'https://neolook.com/archives/1989110610b.jpg']\n",
      "[['이상호', '무릎을 꿇은 청년', '종이에 목판화', '19×24.5cm', '1988'], 'https://neolook.com/archives/1989110611b.jpg']\n",
      "[['이상호', '군중', '종이에 목판화', '21×21.5cm', '1984'], 'https://neolook.com/archives/1989110612b.jpg']\n",
      "[['이상호', '6月', '종이에 목판화', '19×24.5cm', '1987'], 'https://neolook.com/archives/1989110613b.jpg']\n",
      "[['이상호', '지쳐버린 남자', '종이에 목판화', '19×27.5cm', '1987'], 'https://neolook.com/archives/1989110614b.jpg']\n",
      "[['이상호', '고통', '종이에 목판화', '19×28.5cm', '1988'], 'https://neolook.com/archives/1989110615b.jpg']\n",
      "[['이상호', '불', '종이에 목판화', '19.5×23cm', '1987'], 'https://neolook.com/archives/1989110616b.jpg']\n",
      "[['이상호', '모의', '종이에 목판화', '22.5×14.5cm', '1985'], 'https://neolook.com/archives/1989110617b.jpg']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def replaceSrc(imgDesc) :\n",
    "    descIndex = [\"artist\", \"title\", \"media\", \"size\", \"year\"]\n",
    "    replacedDesc = imgDesc\n",
    "    for i in range(len(replacedDesc), 5) :\n",
    "        replacedDesc.append(\"\")\n",
    "    if replacedDesc[2].find(\"cm\") != -1 and replacedDesc[2].find(\"×\") != -1:\n",
    "        replacedDesc[4] = replacedDesc[3]\n",
    "        replacedDesc[3] = replacedDesc[2]\n",
    "        replacedDesc[2] = \"\"\n",
    "    for i in range(len(replacedDesc)) :\n",
    "        if replacedDesc[i] == \"\" :\n",
    "            replacedDesc[i] = f\"{descIndex[i]} : NA\"\n",
    "    return replacedDesc\n",
    "\n",
    "def getImgData(whichVolumePage):\n",
    "    soup = bs(whichVolumePage, \"html.parser\")\n",
    " \n",
    "    description = soup.find(class_=\"archives-description\")\n",
    "    dd = description.find_all(\"dd\")\n",
    "    dt = description.find_all(\"dt\")\n",
    "    \n",
    "    filteredText = []\n",
    "    imgSrcs = soup.find_all('dt')\n",
    "    imgDesc = soup.find_all('dd')\n",
    "    #imgSrcs[0] and imgDesc[0] = 통일전망대 이미지 고정\n",
    "    for i in range(1, len(imgSrcs)):\n",
    "        try:\n",
    "            imgSrcs[i] = imgSrcs[i].find('img')['src']\n",
    "            imgDesc[i] = imgDesc[i].get_text().replace(',', '').replace('\\n', '').strip().replace('\\xa0', '')\n",
    "            imgDesc[i] = imgDesc[i].split('_')\n",
    "            imgDesc[i] = replaceSrc(imgDesc[i])\n",
    "            filteredText.append([imgDesc[i], imgSrcs[i]])\n",
    "        except Exception as e:\n",
    "            print(\"error \", imgSrcs[i], e)\n",
    "            continue\n",
    "\n",
    "    return imgSrcs, imgDesc, filteredText\n",
    "\n",
    "testList = ['19891106b','20000120a','19991207a','19991005a','19970303a','19931126a','19930209a','19921013a','19921002a','19920901b', '19920505a', '19910309a', '20220602a', '20220602c', '20220603i', '20220601b'] #개인전, 그룹전, 그룹전, 저널\n",
    "htmlText = getHtmlText(testList[0])\n",
    "#print(htmlText)\n",
    "imgSrcs, imgDesc, filteredText = getImgData(htmlText)\n",
    "print(*filteredText, sep=\"\\n\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "htmls/2000/20000120a.htm\n",
      "error  'class' index  6  not had class\n",
      "\u001b[95m filtered Text : \u001b[0m  \u001b[95m***\u001b[0m\n",
      "\u001b[95m filtered Text : \u001b[0m 참여작가\n",
      "김수자_김영진_박홍천_배병우_육근병_이불_최정화 \u001b[95m***\u001b[0m\n",
      "\u001b[95m filtered Text : \u001b[0m 아트선재센터\n",
      "서울 종로구 소격동 144-2 번지\n",
      "Tel. 02_733_8942 \u001b[95m***\u001b[0m\n",
      "\u001b[95m filtered Text : \u001b[0m \"『느림』전은 근대화 과정에서 야기되었던 빠른 일상성에서 벗어나 우리의 속도를 찾고자 기획된 전시이다.\"\n",
      "● 아트선재센터가 2000년을 맞아 처음으로 선보이는 전시는 『느림(Slowness of Speed)』이다. 『느림』은 지난 1998년과 1999년 호주 멜버른의 빅토리아 미술관과 시드니의 뉴 사우스 웨일즈 미술관에서 선보여 많은 호응을 얻었던 전시로, 해외 미술관과의 활발한 교류를 통해 우리의 미술과 작가들을 해외에 소개하고 알리는 데에 주력해왔던 아트선재의 활동이 해외에서도 크게 인정을 받게 되었던 계기를 마련해준 전시였다. ● 1998년 7월과 8월 서울 아트선재센터와 경주 아트선재미술관에서 열렸던 호주 현대작가전 『언홈리(Unhomely)』에 대한 교환전으로 기획되었던 이 전시에는 김수자, 김영진, 박홍천, 배병우, 육근병, 이불, 최정화 등 한국의 젊은 작가 7명이 참여하고 있다. ● 『느림』이라는 제목으로 구성된 이 전시는 우리의 근대화 과정에서 단순히 \"빠름\"으로만 변질되어버린 \"속도\"의 개념을 재고해보려는 의도에서 기획된 것이다. 사실 우리의 속도는 변화무쌍했던 근대화 과정에서 보여지는 \"빠름\"이 아니라 오히려 \"산보\", \"소요(逍遙)\"에서 유추되는 \"느림\" 혹은 \"유유자적\"이 아니었을까. 그러나 서구의 문물을 받아들이고 산업화, 과학화, 현대화를 거치는 동안 \"빠름\"은 발전과 진보의 다른 이름으로 대체되어 상대적인 가치우위를 점유하게 되었고, 예술이나 문화의 분야에서도 서구의 그것을 빠르게 따라가는 것만이 발전과 진보를 이루는 것이라는 생각이 만연해 있었다. 이러한 상황들은 각자의 주체적인 생각과는 무관하게 진행되었고, 그 결과 우리 모두는 자신의 속도를 놓쳐버리고 거대한 서구문화담론의 혼란 속에 빠지게 되었다. ● 하지만 동양과 서양, 과거와 현재의 속도 개념이 다르듯이 개개인의 속도에 대한 경험과 기억 역시 다르며, 예술의 분야에 있어서는 더더욱 그러하다. 이러한 자각은 1990년대에 들어서면서부터 자신들만의 고유한 속도를 되찾으려는 젊은 작가들의 움직임을 통해 드러나기 시작했다. 이번 전시를 구성하는 7명의 젊은 작가 김수자, 김영진, 박홍천, 배병우, 육근병, 이불, 최정화는 서로 다른 자신들의 속도를 고수하며 이를 통해 한국미술의 새로운 단면을 보여주려고 노력하는 작가들이다. ● 조각 천들을 모아 바느질을 하고 보따리를 만들던 김수자는 그 보따리들을 트럭에 싣고 산보를 떠나는 작업을 보여준다. 김영진은 자신이 고안해낸 장치를 이용하여 액체 속을 유영(遊泳)하는 텍스트들의 움직임을 보여주며, 이를 통해 시간의 덧없음 혹은 의미를 이야기한다. 빠르게 움직이는 사물들은 사라지고 느리게 움직이거나 혹은 정지해있는 사물들만이 남게 되는 박홍천의 사진은 속도의 한 종류인 \"느림\"을 단적으로 드러내는 작업이다. 배병우의 소나무 사진 역시 한민족의 역사성과 작가의 일상이 오랜 시간동안 투영된 작업이며, 육근병의 비디오 작업은 새벽이 밝아오는 실제시간을 영상에 담아낸 작업이다. 이불은 애니메이션에서 차용한 사이보그의 이미지를 통해 테크놀로지의 빠른 발전과 그 속에서의 여성, 혹은 우리 사회에 대한 고정적인 시각에 대한 의문을 제기하는 작업을 보여준다. 최정화가 보여주는 로봇과 모형 경찰관 역시 산업화, 현대화 속에서 \"빠름\"만을 추구해왔던 사회에 대한 비판적인 발언을 하고 있다. ● 어려웠던 지난 한해를 마무리하고 새 천년을 맞이하면서 의욕적인 출발을 다짐하며 아트선재가 마련한 이번 전시 『느림』은 21세기를 맞이하는 현시점에서 우리의 미술의 앞날을 가늠해볼 수 있는 좋은 기회를 제공할 뿐만 아니라 우리 미술계에 대한 아트선재의 의지와 약속을 보여주는 기회가 되리라 생각한다. ■\n",
      "김윤경 \u001b[95m***\u001b[0m\n",
      "\u001b[95m filtered Text : \u001b[0m Vol.20000120a\n",
      "느림_Slowness of Speed展 \u001b[95m***\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def getDescData(whichVolumePage):\n",
    "    soup = bs(whichVolumePage, \"html.parser\")\n",
    "\n",
    "    description = soup.find(class_=\"archives-description\")\n",
    "    descText = soup.find_all('p')\n",
    "    filteredText = \"\"\n",
    "    for i in reversed(range(len(descText))):\n",
    "        text = descText[i]\n",
    "        try:\n",
    "            if str(text[\"class\"]).find('line') != -1:\n",
    "                del descText[i]\n",
    "        except Exception as e:\n",
    "            print(\"error \", e, \"index \", i, \" not had class\")\n",
    "            continue\n",
    "    for text in descText:\n",
    "        text = text.get_text().split('\\n')\n",
    "        text = map(lambda x: x.strip(), text)\n",
    "        text = filter(lambda x: len(x) > 1, text)\n",
    "        text = filter(lambda x: x != '\\xa0' and x != ' ' , text)\n",
    "        text = filter(lambda x: x.find(\"위 이미지를\") == -1, text)\n",
    "        text = '\\n'.join(text)\n",
    "        print(f\"\\033[95m filtered Text : \\033[0m {text} \\033[95m***\\033[0m\")\n",
    "        filteredText += text + '\\n'\n",
    "    filteredText.replace('\\n\\n', '\\n').replace('\\xa0', '')\n",
    "\n",
    "    return imgSrcs, imgDesc, filteredText\n",
    "\n",
    "testList = ['19891106b', '20000120a', '19991207a', '19991005a', '19970303a', '19931126a', '19930209a', '19921013a',\n",
    "            '19921002a', '19920901b', '19920505a', '19910309a', '20220602a', '20220602c', '20220603i', '20220601b']  # 개인전, 그룹전, 그룹전, 저널\n",
    "htmlText = getHtmlText(testList[1])\n",
    "#print(htmlText)\n",
    "imgSrcs, imgDesc, filteredText = getDescData(htmlText)\n",
    "#print(filteredText)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e77c429cd93eb5d3bf847b18e0149277fc429c6d304430fec0191ef6177f54a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
